# -*- coding: utf-8 -*-
"""alzheimer-brain-mri-classifier-effnetb0-99-acc.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KQfNlM8B4CHz3UrShr-EnQSmNnIBgW-X

# 1. Imports and setup
"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

!kaggle datasets download -d sachinkumar413/alzheimer-mri-dataset

import zipfile
zip_ref = zipfile.ZipFile('/content/alzheimer-mri-dataset.zip')
zip_ref.extractall('/content/Data')
zip_ref.close()

import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import random
import os
import pathlib
from sklearn.metrics import confusion_matrix
from tensorflow.keras.preprocessing import image_dataset_from_directory
import itertools

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
for dirpath, dirnames, filenames in os.walk("/kaggle/input"):
    print(f"{len(dirnames)} dirs and {len(filenames)} images in '{dirpath}'")

data_dir = "/content/Data/Dataset/"
path_dir = pathlib.Path("/content/Data/Dataset/")
class_names = np.array(sorted([item.name for item in path_dir.glob('*')]))
print(class_names)

"""# 2. Explore individual images"""

def view_random_image(target_dir, target_class):
    target_folder = target_dir + target_class
    random_image = random.sample(os.listdir(target_folder), 1)
    img = mpimg.imread(target_folder + "/" + random_image[0])
    plt.imshow(img)
    plt.title(target_class)
    plt.axis("off");

    print(f"Image shape: {img.shape}")
    return img

img = view_random_image(data_dir, class_names[0])

img = view_random_image(data_dir, class_names[1])

img = view_random_image(data_dir, class_names[2])

img = view_random_image(data_dir, class_names[3])

"""# 3. Model Tuning

## Split and preprocess data
"""

# For replicable results
SEED = 0
# Size of the images is (128,128)
IMAGE_SIZE = (128, 128)
# Default batch size
BATCH_SIZE = 32
# Images are grayscale
COLOR_MODE = "grayscale"
# 20% test split
VAL_SPLIT = 0.2

tf.random.set_seed(SEED)
np.random.seed(SEED)
train_data = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    label_mode='categorical',
    validation_split=VAL_SPLIT,
    subset="training",
    seed=SEED,
    color_mode=COLOR_MODE,
    image_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
)
valid_data = tf.keras.preprocessing.image_dataset_from_directory(
    data_dir,
    validation_split=VAL_SPLIT,
    subset="validation",
    label_mode='categorical',
    seed=SEED,
    color_mode=COLOR_MODE,
    image_size=IMAGE_SIZE,
    batch_size=BATCH_SIZE,
)

"""## Model creation and compilation (EfficientNet B0)"""

base_model = tf.keras.applications.EfficientNetB0(include_top=False)
base_model.trainable = True
inputs = tf.keras.layers.Input(shape=(IMAGE_SIZE+(1,)), name="input_layer")
# Efficient net model has the normalizing layer builtin
x = base_model(inputs)
x = tf.keras.layers.GlobalAveragePooling2D(name="global_average_pooling_layer")(x)
outputs = tf.keras.layers.Dense(len(class_names), activation="softmax", name="output_layer")(x)

model = tf.keras.Model(inputs, outputs)

# Default Learning rate
LR = 0.001

model.compile(loss="categorical_crossentropy",
                optimizer=tf.keras.optimizers.Adam(learning_rate=LR),
                metrics=["accuracy"])

model.summary()

"""## Fit and evaluate model"""

# Epochs
EPOCHS = 50
history = model.fit(train_data,
                      validation_data=valid_data,
                      epochs=EPOCHS,
                      verbose=False
                      )

pd.DataFrame(history.history).plot(figsize=(10, 7));

model.evaluate(valid_data)

model.save('alzheimer.h5')

"""# 4. Final thoughts

The accuracy on unseen images is around 99%. This is a significantly better result than the previous version of this notebook, with a 75% accuracy.

What was the big change? Simply make the Efficientnet model trainable from start. The course I was following until now mentiones it's best to train your model first without making it trainable, then make the last layers trainable and compare results. Thanks to Gerry (gpiosenka) beating me to a pulp in my color polygon dataset I learned it's actually best to make the model trainable from the start, it's worth it **a lot**.
"""